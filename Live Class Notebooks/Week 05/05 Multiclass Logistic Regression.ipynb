{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imcNmFXhPdCh"
   },
   "outputs": [],
   "source": [
    "# Import our standard libraries.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style='darkgrid')  # default style\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(precision=3, suppress=True)  # improve float readability\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4mROCY5wAX4"
   },
   "source": [
    "## Iris Classification\n",
    "\n",
    "We will train a classifier to predict 3 iris varieties from 4 features of each flower. Note: we are not doing image classification here!\n",
    "\n",
    "![An image](https://drive.google.com/uc?id=12gf4Q0K45gvw-tUDt_sWsbAl-f0klhib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "37XEUjK4ulzp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "Y shape: (150,)\n",
      "feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "class names: ['setosa' 'versicolor' 'virginica']\n",
      "First example: [5.1 3.5 1.4 0.2] 0\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('feature names:', feature_names)\n",
    "print('class names:', class_names)\n",
    "print('First example:', X[0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3GC13Sf219q"
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "* Shuffle\n",
    "* Split into train/test\n",
    "* Apply mean and variance normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-sa_lrwU1oiT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.833, 3.088, 3.738, 1.201])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.849, 0.441, 1.801, 0.782])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "shuffled_indices = np.random.permutation(range(len(Y)))\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "X_train = X[0:100]\n",
    "Y_train = Y[0:100]\n",
    "X_test = X[100:150]\n",
    "Y_test = Y[100:150]\n",
    "\n",
    "X_train_means = np.mean(X_train, axis=0)\n",
    "X_train_stds = np.std(X_train, axis=0)\n",
    "X_train = (X_train - X_train_means) / X_train_stds\n",
    "X_test = (X_test - X_train_means)/ X_train_stds\n",
    "\n",
    "display(X_train_means)\n",
    "display(X_train_stds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jIgCYbiVAz3"
   },
   "source": [
    "## Sparse vs Dense Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8bcduWsAbCRl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert Y from sparse to dense if needed\n",
    "# one-hot [0, 0, 1] -> 2\n",
    "# one-hot [0, 1, 0] -> 1\n",
    "# one-hot [1, 0, 0] -> 0\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "print(Y_train_dense.shape)\n",
    "print(Y_train_dense[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS7LIrIlVd2E"
   },
   "source": [
    "## Softmax Regression Functional Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tdGfEoDovBm"
   },
   "source": [
    "We will use *softmax regression*, which extends *logistic regression* to the multiclass setting. Our model will make predictions for input examples $X$ by:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{Y} = h_W(X) = \\phi(XW^T) =\n",
    "\\phi\\begin{pmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n",
    "x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "w_{0,0} & w_{1,0} & w_{2,0} \\\\\n",
    "w_{0,1} & w_{1,1} & w_{2,1} \\\\\n",
    "w_{0,2} & w_{1,2} & w_{2,2} \\\\\n",
    "w_{0,3} & w_{1,3} & w_{2,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "A few notes about this computation:\n",
    "\n",
    "* Our X has shape (100 x 4): 100 examples and 4 features\n",
    "* Our W has shape (3 x 4): 3 classes and 4 features. The indices above are reversed because we've taken the transpose of W: the first column of $W^T$ contains the weights for the first class.\n",
    "* The result will have shape (100 x 3): 3 probabilities corresponding to the 3 classes for each of the 100 examples.\n",
    "* $\\phi$ is the softmax function: $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$. It is applied to the rows of $XW^T$.\n",
    "\n",
    "More detailed background [here](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAoIx-nkXhD-"
   },
   "source": [
    "## Softmax Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Hpah13BcCVXo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09  0.245 0.665]\n",
      " [0.016 0.117 0.867]]\n"
     ]
    }
   ],
   "source": [
    "# Remember the sigmoid function.\n",
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Our softmax function will normalize over the rows of the input matrix.\n",
    "def softmax(z):\n",
    "  \"\"\"z has shape (m, n): examples, classes\"\"\"\n",
    "  (m, n) = z.shape\n",
    "\n",
    "  # First exponentiate each value\n",
    "  exps = np.exp(z)\n",
    "\n",
    "  # Get the sum of each row and normalize\n",
    "  row_sums = np.sum(exps, axis=1)\n",
    "  for i in range(m):\n",
    "    exps[i,:] /= row_sums[i]\n",
    "  \n",
    "  # Fancy/tricky way to do row-wise sums in numpy:\n",
    "  # return np.divide(exps.T, np.sum(exps, axis=1)).T\n",
    "\n",
    "  return exps\n",
    "\n",
    "# Try an example.\n",
    "v = np.array([[1,2,3],\n",
    "              [0,2,4]])\n",
    "print(softmax(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLh6VWUfGm7_"
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "Now, given some initial parameter values (below), compute the model's initial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pGg1Ll4I4jR6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "label predictions:\n",
      " [0 0 0 0 0 0]\n",
      "true labels:\n",
      " [0 0 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Initial parameter values.\n",
    "# W = np.random.uniform(size=(3,4))\n",
    "W = np.ones((3,4))\n",
    "\n",
    "# Compute predictions.\n",
    "preds = softmax(np.dot(X_train, W.T))\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('label predictions:\\n', np.argmax(preds, axis=1)[:6])\n",
    "print('true labels:\\n', Y_train[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIbpXB4ZHPvO"
   },
   "source": [
    "## Cross-Entropy Loss\n",
    "\n",
    "We'll use the general form of *cross-entropy* loss:\n",
    "\n",
    "\\begin{align}\n",
    "CrossEntropyLoss = \\frac{1}{m} \\sum_i \\sum_j -y_j\\log(\\hat{y_j})\n",
    "\\end{align}\n",
    "\n",
    "In this formula:\n",
    "\n",
    "* $j$ indexes the classes (in our case [0,1,2]) and each $y$ has a dense representation like [0,0,1] which indicates class 2.\n",
    "* *i* indexes over training examples, so we're computing an average loss (as usual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lWxpr2OogN70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681093\n"
     ]
    }
   ],
   "source": [
    "def ce_loss(preds, Y):\n",
    "  \"\"\"\n",
    "    preds are (m,n) m = number of examples, n = number of classes\n",
    "    Y is (m,) -- array of sparse labels \n",
    "    preds[0] = [.1, .1, .8] Y[0] = 2 Y_dense[0] = [0, 0, 1]\n",
    "  \"\"\"\n",
    "  # Get the number of examples\n",
    "  m = Y.shape[0]\n",
    "\n",
    "  # Compute the first sum, the cross-entropy for each example, using\n",
    "  # the rows of the predictions and corresponding labels.\n",
    "  # Note that we need the dense (one-hot) labels.\n",
    "  Y_dense = tf.keras.utils.to_categorical(Y)\n",
    "  # [.1, .1, .8] [0, 0, 1] -> [0, 0, -1*log(.8)] -> -1*log(.8)\n",
    "  cross_entropy_values = - np.sum(Y_dense * np.log(preds), axis=1)\n",
    "\n",
    "  # Here's a more efficient but tricky way to do this:\n",
    "  # cross_entropy_values = -np.log(preds[range(m), Y])\n",
    "\n",
    "  # Sum the per-example cross-entropy values.\n",
    "  loss = np.sum(cross_entropy_values) / m\n",
    "\n",
    "  return loss\n",
    "\n",
    "#print(ce_loss(np.array([.1, .1, .8]), np.array([2])))\n",
    "print(ce_loss(preds, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaRg8b1F93w9"
   },
   "source": [
    "## Computing the Gradient\n",
    "\n",
    "Again, it will turn out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)^TX\n",
    "\\end{align}\n",
    "\n",
    "Remember that our parameters $W$ are represented by a matrix of shape (3 x 4): 3 classes and 4 features. The gradient will include a partial derivative for every parameter, and is an average over gradients computed on each training example.\n",
    "\n",
    "Let's review the matrix shapes:\n",
    "\n",
    "* $h_W(X)$ is (100 x 3): 3 probabilities for each example.\n",
    "* $Y$ is (100 x 3): this is the dense (one-hot) version of the labels, matching the shape of the predictions.\n",
    "* $X$ is (100 x 4): 4 features for each example.\n",
    "* The resulting product is (3 x 100)(100 x 4), giving a (3 x 4) output, which matches the shape of our parameters $W$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0-j0soKK2qfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient:\n",
      " [[ 0.334 -0.27   0.441  0.427]\n",
      " [-0.014  0.207 -0.086 -0.053]\n",
      " [-0.32   0.063 -0.354 -0.374]]\n"
     ]
    }
   ],
   "source": [
    "# y' = [.1, .2, .7]  y = [0, 0, 1]  diff = y' - y = [.1, .2, -.3]\n",
    "# d1 = [.1, .2, -.3]  x1 = [1, 2, 3, 4]\n",
    "# (3 x 100) (100 x 4) -> (3 x 4)\n",
    "# [ [ .1*1,  .1*2,  .1*3,  .1*4 ]\n",
    "#   [ .2*1,  .2*2,  .2*3,  .2*4 ]\n",
    "#   [-.3*1, -.3*2, -.3*3, -.3*4 ]\n",
    "# ]\n",
    "#\n",
    "# We need the dense version of Y here\n",
    "m = Y_train.shape[0]\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "diff = preds - Y_train_dense\n",
    "gradient = np.dot(diff.T, X_train) / m\n",
    "print('gradient:\\n', gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ExL4G-pMAXvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.667]\n",
      " [ 0.333]\n",
      " [ 0.333]]\n",
      "[[-0.981  0.707 -1.243 -1.279]]\n",
      "gradient:\n",
      " [[ 0.654 -0.471  0.829  0.853]\n",
      " [-0.327  0.236 -0.414 -0.426]\n",
      " [-0.327  0.236 -0.414 -0.426]]\n"
     ]
    }
   ],
   "source": [
    "# Simplify and just compute the gradient for the first training example.\n",
    "print(diff[0:1].T)\n",
    "print(X_train[0:1])\n",
    "print('gradient:\\n', np.dot(diff[0:1].T, X_train[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZDyrbc42rcF"
   },
   "source": [
    "## Running Gradient Descent\n",
    "\n",
    "Let's put together the code for a single gradient descent step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Zl_Nu_wB8ar4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [0 0 2 0 0 1]\n",
      "predictions:\n",
      " [[0.956 0.036 0.008]\n",
      " [0.921 0.069 0.01 ]\n",
      " [0.005 0.165 0.83 ]\n",
      " [0.971 0.017 0.012]\n",
      " [0.987 0.005 0.008]\n",
      " [0.041 0.619 0.339]]\n",
      "loss: 0.38293292380328936\n",
      "gradient:\n",
      " [[ 0.013 -0.024  0.027  0.025]\n",
      " [-0.006  0.03  -0.009  0.006]\n",
      " [-0.007 -0.006 -0.018 -0.031]]\n",
      "weights:\n",
      " [[0.528 1.549 0.258 0.293]\n",
      " [1.014 0.42  1.163 0.988]\n",
      " [1.458 1.031 1.579 1.719]]\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent\n",
    "m, n = X.shape  # m = number of examples; n = number of features (including bias)\n",
    "learning_rate = 0.01\n",
    "\n",
    "for _ in range(1000):\n",
    "  preds = softmax(np.dot(X_train, W.T))\n",
    "  loss = ce_loss(preds, Y_train)\n",
    "  gradient = np.dot((preds - tf.keras.utils.to_categorical(Y_train)).T, X_train) / m\n",
    "  W = W - learning_rate * gradient\n",
    "\n",
    "print('labels:\\n', Y_train[:6])\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('gradient:\\n', gradient)\n",
    "print('weights:\\n', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q72Tu_n_LlO"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tj3z7t6-_PZ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = softmax(np.dot(X_test, W.T))\n",
    "test_pred_labels = np.argmax(test_preds, axis=1)\n",
    "print('Accuracy:', np.mean(test_pred_labels == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xcq8zqKDALmC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = tf.math.confusion_matrix(Y_test, test_pred_labels)\n",
    "ax = sns.heatmap(cf, annot=True, fmt='.3g', cmap='Blues',\n",
    "                 xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMsSJ-ZD_12e"
   },
   "source": [
    "## Now with TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jisaFtGY__KL"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=3,                     # output dim\n",
    "    input_shape=[4],             # input dim\n",
    "    use_bias=False,              # we included the bias in X\n",
    "    activation='softmax',        # apply a sigmoid to the output\n",
    "    kernel_initializer=tf.ones_initializer,  # initialize params to 1\n",
    "))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3PQ-RDwXCKVt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "loss: 0.9861212372779846\n",
      "W:\n",
      " [[ 0.021  2.847 -0.756 -0.685]\n",
      " [ 1.528 -0.422  2.125  0.343]\n",
      " [ 1.438  0.888  2.081  2.913]]\n"
     ]
    }
   ],
   "source": [
    "# As above, get predictions for the current model first.\n",
    "preds = model.predict(X)\n",
    "\n",
    "# Do a single gradient update.\n",
    "history = model.fit(\n",
    "  x = X_train,\n",
    "  y = Y_train,\n",
    "  epochs=100,\n",
    "  batch_size=10,\n",
    "  verbose=0)\n",
    "\n",
    "# Show the loss (before the update) and the new weights.\n",
    "loss = history.history['loss'][0]\n",
    "weights = model.layers[0].get_weights()[0].T\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('W:\\n', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QAmb6PMCTVET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9861212372779846, 0.7895212769508362, 0.6531801819801331, 0.5687041878700256, 0.5139146447181702, 0.475040465593338, 0.4499419331550598, 0.43017056584358215, 0.41438835859298706, 0.4021686911582947, 0.3919590711593628, 0.38354191184043884, 0.376773864030838, 0.3702426850795746, 0.365169495344162, 0.35994112491607666, 0.35569459199905396, 0.3523702919483185, 0.3482089936733246, 0.34495997428894043, 0.3422093689441681, 0.338947057723999, 0.33657974004745483, 0.3343557119369507, 0.3321506083011627, 0.32985004782676697, 0.3286467492580414, 0.3258843719959259, 0.32430267333984375, 0.32251235842704773, 0.3212480843067169, 0.3197791278362274, 0.31841370463371277, 0.3175007104873657, 0.31556636095046997, 0.31517645716667175, 0.31386059522628784, 0.3126794099807739, 0.31122708320617676, 0.31041815876960754, 0.30959853529930115, 0.30868643522262573, 0.30765214562416077, 0.3069990575313568, 0.3060045540332794, 0.30539774894714355, 0.3046712577342987, 0.3038554787635803, 0.3034415543079376, 0.3027178943157196, 0.30220457911491394, 0.30206507444381714, 0.3007356822490692, 0.30064743757247925, 0.29984354972839355, 0.29967087507247925, 0.29919877648353577, 0.2983909547328949, 0.2979625463485718, 0.2973178029060364, 0.29693105816841125, 0.29656559228897095, 0.29631879925727844, 0.2961954176425934, 0.29533717036247253, 0.2950129806995392, 0.29488423466682434, 0.29454633593559265, 0.2941606044769287, 0.29405677318573, 0.29330965876579285, 0.29370367527008057, 0.2926645576953888, 0.29304537177085876, 0.2924156188964844, 0.29192349314689636, 0.2925483286380768, 0.2919873297214508, 0.29127880930900574, 0.2913200855255127, 0.2906094491481781, 0.2911719083786011, 0.2902984917163849, 0.2899510860443115, 0.2898905873298645, 0.28975069522857666, 0.28968989849090576, 0.28942278027534485, 0.2890181541442871, 0.2887568771839142, 0.2884890139102936, 0.28826314210891724, 0.2891196012496948, 0.2879788279533386, 0.2875300645828247, 0.28776681423187256, 0.28746628761291504, 0.2872590124607086, 0.28793197870254517, 0.286726176738739]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DuKK7l4fTktl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.86\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3388510048389435"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "test_preds_labels = np.argmax(test_preds, axis=1)\n",
    "accuracy = np.mean(test_preds_labels == Y_test)\n",
    "print(accuracy)\n",
    "model.evaluate(x=X_test, y=Y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOF/SzfGqGLnE58b8QnQuUU",
   "name": "03 Multiclass Logistic Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
